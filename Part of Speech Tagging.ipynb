{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART OF SPEECH TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('refuse', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('let', 'VB'),\n",
       " ('this', 'DT'),\n",
       " ('refuse', 'NN'),\n",
       " ('get', 'VB'),\n",
       " ('me', 'PRP'),\n",
       " ('down', 'RP')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I refuse to let this refuse get me down\"\n",
    "\n",
    "tokenized_words = word_tokenize(text)\n",
    "tagged_words = nltk.pos_tag(tokenized_words)\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bear', 'NNP'),\n",
       " ('with', 'IN'),\n",
       " ('me', 'PRP'),\n",
       " (',', ','),\n",
       " ('this', 'DT'),\n",
       " ('effort', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('soon', 'RB'),\n",
       " ('bear', 'JJ'),\n",
       " ('fruit', 'NN'),\n",
       " (',', ','),\n",
       " ('otherwise', 'RB'),\n",
       " ('we', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('have', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('run', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('bear', 'NN')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"Bear with me, this effort with soon bear fruit, \n",
    "          otherwise we'll have to run from the bear\"\"\"\n",
    "\n",
    "tokenized_words = word_tokenize(text)\n",
    "tagged_words = nltk.pos_tag(tokenized_words)\n",
    "tagged_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING NOUNS FROM THE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "para=\"\"\"One of the most common AI techniques used for processing big data is machine learning, a self-adaptive algorithm that gets increasingly better analysis and patterns with experience or with newly added data.\n",
    "\n",
    "If a digital payments company wanted to detect the occurrence or potential for fraud in its system, it could employ machine learning tools for this purpose. The computational algorithm built into a computer model will process all transactions happening on the digital platform, find patterns in the data set, and point out any anomaly detected by the pattern.\n",
    "\n",
    "Deep learning, a subset of machine learning, utilizes a hierarchical level of artificial neural networks to carry out the process of machine learning. The artificial neural networks are built like the human brain, with neuron nodes connected together like a web. While traditional programs build analysis with data in a linear way, the hierarchical function of deep learning systems enables machines to process data with a nonlinear approach.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'One of the most common AI techniques used for processing big data is machine learning, a self-adaptive algorithm that gets increasingly better analysis and patterns with experience or with newly added data.\\n\\nIf a digital payments company wanted to detect the occurrence or potential for fraud in its system, it could employ machine learning tools for this purpose. The computational algorithm built into a computer model will process all transactions happening on the digital platform, find patterns in the data set, and point out any anomaly detected by the pattern.\\n\\nDeep learning, a subset of machine learning, utilizes a hierarchical level of artificial neural networks to carry out the process of machine learning. The artificial neural networks are built like the human brain, with neuron nodes connected together like a web. While traditional programs build analysis with data in a linear way, the hierarchical function of deep learning systems enables machines to process data with a nonlinear approach.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AI', 'techniques', 'data', 'machine', 'learning', 'algorithm', 'analysis', 'patterns', 'experience', 'data', 'payments', 'company', 'occurrence', 'potential', 'fraud', 'system', 'machine', 'learning', 'tools', 'purpose', 'algorithm', 'computer', 'model', 'transactions', 'platform', 'patterns', 'data', 'set', 'pattern', 'Deep', 'learning', 'subset', 'machine', 'learning', 'level', 'networks', 'process', 'machine', 'learning', 'networks', 'brain', 'nodes', 'web', 'programs', 'analysis', 'data', 'way', 'function', 'systems', 'machines', 'data', 'approach']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = word_tokenize(para)\n",
    "extracting_nouns = [word for (word, pos) in nltk.pos_tag(tokenized_words) if(pos[:2] == 'NN')]\n",
    "print(extracting_nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXTRACTING VERBS FROM THE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['used', 'processing', 'is', 'gets', 'added', 'wanted', 'detect', 'employ', 'built', 'process', 'happening', 'find', 'point', 'detected', 'utilizes', 'carry', 'are', 'built', 'connected', 'build', 'learning', 'enables', 'process']\n"
     ]
    }
   ],
   "source": [
    "tokenized_words = word_tokenize(para)\n",
    "extracting_verbs = [word for (word, pos) in nltk.pos_tag(tokenized_words) if(pos[:2] == 'VB')]\n",
    "print(extracting_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
